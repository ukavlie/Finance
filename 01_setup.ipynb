{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initial setup is for first use only. It will create an initial database in SQL and do an initial scraping of both tradable stocks in Revolut and stocks on the S&P500. It will then do a first download of financial data and store the metrics to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# finacials\n",
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "# web scraping\n",
    "import requests\n",
    "import lxml.html as lh\n",
    "import re\n",
    "import unicodedata\n",
    "import webbrowser\n",
    "\n",
    "# sql\n",
    "import mysql.connector\n",
    "\n",
    "# other\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mysql.connector.connect(host        = \"localhost\",\n",
    "                             user        = \"root\",\n",
    "                             passwd      = \"xxxxxxxx\",\n",
    "                             auth_plugin = \"mysql_native_password\",\n",
    "                             database    = \"investing\"\n",
    "                            )\n",
    "\n",
    "my_cursor = db.cursor(buffered = True)\n",
    "\n",
    "today    = datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revolut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ed2eebdd614883ad30c7f0378c4f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=928.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# requesting the data\n",
    "url = \"https://globefunder.com/revolut-stocks-list/\"\n",
    "page = requests.get(url)\n",
    "doc = lh.fromstring(page.content)\n",
    "tr_element = doc.xpath(\"//tr\")\n",
    "\n",
    "# extracting the columns\n",
    "col=[]\n",
    "for tr in tr_element[0]:\n",
    "    name = tr.text_content()\n",
    "    name = re.sub('\\n', '', name)\n",
    "    col.append((name,[]))\n",
    "\n",
    "# extracting the values in the columns\n",
    "for j in range(1,len(tr_element)):\n",
    "    T = tr_element[j]\n",
    "    for i, tr in enumerate(T.iterchildren()):\n",
    "        data = tr.text_content()\n",
    "        data = re.sub(\"\\n\", \"\", data)\n",
    "        data = re.sub(\"\\.\", \"-\", data)\n",
    "        col[i][1].append(data)\n",
    "\n",
    "        \n",
    "# transforming to dataframe\n",
    "Dict = {title:column for (title,column) in col}\n",
    "rev   = pd.DataFrame(Dict)\n",
    "rev.columns = [\"#\", \"company\", \"ticker\", 'Stock price (USD)',\"sector_1\", \"industry\", \"market\"]\n",
    "\n",
    "# extracting ticker and company name\n",
    "rev = rev.loc[:, [\"ticker\", \"company\", \"sector_1\"]]\n",
    "\n",
    "# dictionary of different sectors\n",
    "sector_dict = {\"Industrials\"           : \"Industrials\", \n",
    "               \"Healthcare\"            : \"Health Care\",\n",
    "               \"Technology\"            : \"Information Technology\",\n",
    "               \"Communication Services\": \"Communication Services\",\n",
    "               \"Consumer Cyclical\"     : \"Consumer Discretionary\",\n",
    "               \"Utilities\"             : \"Utilities\",\n",
    "               \"Financial Services\"    : \"Financials\",\n",
    "               \"Real Estate\"           : \"Real Estate\",\n",
    "               \"Basic Materials\"       : \"Materials\",\n",
    "               \"Consumer Defensive\"    : \"Consumer Staples\",\n",
    "               \"Energy\"                : \"Energy\"\n",
    "              }\n",
    "\n",
    "# getting the RIGTH sectors\n",
    "startTime = datetime.now()\n",
    "sectors = []\n",
    "\n",
    "# looping over all the tickers\n",
    "#for index, value in rev.iterrows():\n",
    "for index in trange(len(rev)):\n",
    "    \n",
    "    # sector one in lower cap\n",
    "    rev.loc[index, \"sector_1\"] = str.lower(rev.loc[index, \"sector_1\"])\n",
    "    \n",
    "    # extracting sectors from yf\n",
    "    sctr = yf.Ticker(rev.loc[index, \"ticker\"])\n",
    "    try:\n",
    "        sctr = sctr.info[\"sector\"]\n",
    "        \n",
    "        # transforming sectors\n",
    "        for k in sector_dict.keys():\n",
    "            if k == sctr:\n",
    "                sctr = sector_dict[k]\n",
    "        sectors.append(sctr)\n",
    "        \n",
    "    # if no sectors, unknown\n",
    "    except:\n",
    "        sectors.append(\"UNKNOWN\")\n",
    "\n",
    "        \n",
    "# creating a second sector column\n",
    "rev[\"sector_2\"] = sectors\n",
    "\n",
    "# accounting for unknown sectors from previous task\n",
    "last_sect = []\n",
    "\n",
    "for index, value in rev.iterrows():\n",
    "    \n",
    "    # comparing unknowns original sector with all companies within same sector\n",
    "    if rev.loc[index,\"sector_2\"] == \"UNKNOWN\":\n",
    "        org_sect = [rev.loc[index,\"sector_1\"]][0]\n",
    "        new_sect = rev[rev.loc[:,\"sector_1\"] == org_sect][\"sector_2\"].value_counts().idxmax()\n",
    "        last_sect.append(new_sect)\n",
    "        \n",
    "    else:\n",
    "        last_sect.append(rev.loc[index,\"sector_2\"])\n",
    "rev[\"sector_3\"] = last_sect\n",
    "\n",
    "# tossing previous sector columns\n",
    "rev = rev.loc[:,[\"ticker\", \"company\", \"sector_3\"]]\n",
    "rev.columns = [\"ticker\", \"company\", \"sector\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requesting the data\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "page = requests.get(url)\n",
    "doc = lh.fromstring(page.content)\n",
    "tr_element = doc.xpath(\"//tr\")\n",
    "\n",
    "# extracting the columns\n",
    "col=[]\n",
    "for tr in tr_element[0]:\n",
    "    name = tr.text_content()\n",
    "    name = re.sub('\\n', '', name)\n",
    "    col.append((name,[]))\n",
    "    \n",
    "# extracting the values for CURRENT constituents\n",
    "for j in range(1,506):\n",
    "    T = tr_element[j]\n",
    "    for i, tr in enumerate(T.iterchildren()):\n",
    "        data = tr.text_content()\n",
    "        data = re.sub(\"\\n\", \"\", data)\n",
    "        data = re.sub(\"\\.\", \"-\", data)\n",
    "        col[i][1].append(data)\n",
    "\n",
    "        \n",
    "# transforming to dataframe\n",
    "Dict = {title:column for (title,column) in col[:4]}\n",
    "sp   = pd.DataFrame(Dict)\n",
    "sp.columns = [\"ticker\", \"company\", \"sec_filing\", \"sector\"]\n",
    "\n",
    "sp = sp.loc[:, [\"ticker\", \"company\", \"sector\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the two Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the two stock lists\n",
    "full_stk = pd.concat([rev, sp])\n",
    "\n",
    "# dropping duplicates, keeping revolut\n",
    "full_stk = full_stk.drop_duplicates(subset = \"ticker\", keep = \"last\")\n",
    "\n",
    "# resetting index\n",
    "full_stk = full_stk.reset_index(drop = True)\n",
    "\n",
    "# declaring affiliation\n",
    "sp[\"SP\"] = 1\n",
    "rev[\"Revolut\"] = 1\n",
    "full_stk = full_stk.merge(sp.loc[:,[\"ticker\", \"SP\"]], on = \"ticker\", how = \"outer\")\n",
    "full_stk = full_stk.merge(rev.loc[:,[\"ticker\", \"Revolut\"]], on = \"ticker\", how = \"outer\")\n",
    "\n",
    "# replacing nan with 0\n",
    "full_stk = full_stk.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Financial Download\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81807c9cb709457b890c5c07dd8c76a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1061.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "# list of stocks to loop over\n",
    "stocks = list(full_stk[\"ticker\"])\n",
    "\n",
    "\n",
    "# empty list for failed extractions\n",
    "fails  = []\n",
    "\n",
    "# empty item for df\n",
    "all_stats = None\n",
    "\n",
    "# looping over stocks\n",
    "for i in trange(len(stocks)):\n",
    "    \n",
    "    try:\n",
    "        # downloading statistical data\n",
    "        stock_stats = pd.json_normalize(YahooFinancials(stocks[i]).get_key_statistics_data()[stocks[i]])\n",
    "\n",
    "        # add additional metrics\n",
    "\n",
    "        stock_stats[\"pricetoSales\"] = YahooFinancials(stocks[i]).get_price_to_sales()\n",
    "        \n",
    "        stock_stats[\"ticker\"]       = stocks[i]\n",
    "\n",
    "\n",
    "        # either create or add to df\n",
    "        if all_stats is None:\n",
    "            all_stats = stock_stats\n",
    "        else:\n",
    "            all_stats = pd.concat([all_stats, stock_stats], axis = 0)\n",
    "\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        # listing failed attempts\n",
    "        fails.append(stocks[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making copy of data\n",
    "stats = all_stats.copy()\n",
    "\n",
    "# converting to numeric values\n",
    "for i in stats:\n",
    "    try:\n",
    "        stats[i] = pd.to_numeric(stats[i])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "# dropping columns with no information\n",
    "for col in stats:\n",
    "    if stats[col].isnull().sum() == len(stats):\n",
    "        stats = stats.drop(col, axis = 1)\n",
    "        \n",
    "# adding trailing P/E\n",
    "stats[\"trailingPE\"] = stats[\"forwardPE\"]*stats[\"forwardEps\"]/stats[\"trailingEps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing in SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in full_stk.sector.unique():\n",
    "    my_cursor.execute(\"INSERT INTO sectors (sector) VALUES (%s)\",(i,))\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching sectors and sector_ids\n",
    "my_cursor.execute(\"SELECT sector_id, sector FROM sectors\")\n",
    "sectors = []\n",
    "for i in my_cursor:\n",
    "    sectors.append(i)\n",
    "    \n",
    "# creating dataframe of data\n",
    "sectors = pd.DataFrame(sectors, columns = [\"sector_id\", \"sector\"])\n",
    "\n",
    "# adding sector_ids to stock list\n",
    "full_stk = full_stk.merge(sectors, on = \"sector\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting stocks into stock table\n",
    "for index, row in full_stk.iterrows():\n",
    "    my_cursor.execute(\"INSERT INTO stock (ticker, company, sector_id) VALUES (%s,%s,%s)\",\n",
    "                      (full_stk.loc[index,\"ticker\"],\n",
    "                       full_stk.loc[index,\"company\"],\n",
    "                       int(full_stk.loc[index,\"sector_id\"]),)\n",
    "                     )\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching stock_id and ticker \n",
    "my_cursor.execute(\"SELECT stock_id, ticker from stock\")\n",
    "short_stk = []\n",
    "for i in my_cursor:\n",
    "    short_stk.append(i)\n",
    "\n",
    "# creating dataframe of data\n",
    "short_stk = pd.DataFrame(short_stk, columns = [\"stock_id\", \"ticker\"])\n",
    "\n",
    "# adding stock_ids to stock list\n",
    "full_stk = full_stk.merge(short_stk, on = \"ticker\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S&P500\n",
    "for index, row in full_stk[full_stk.loc[:,\"SP\"] == 1].iterrows():\n",
    "    my_cursor.execute(\"INSERT INTO sandp (stock_id, from_date) VALUES (%s,%s)\",\n",
    "                      (int(full_stk.loc[index, \"stock_id\"]),\n",
    "                       today,\n",
    "                      )\n",
    "                     )\n",
    "    \n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revolut\n",
    "for index, row in full_stk[full_stk.loc[:,\"Revolut\"] == 1].iterrows():\n",
    "    my_cursor.execute(\"INSERT INTO revolut (stock_id, from_date) VALUES (%s,%s)\",\n",
    "                      (int(full_stk.loc[index, \"stock_id\"]),\n",
    "                       today,\n",
    "                      )\n",
    "                     )\n",
    "    \n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging statistical information with stock information\n",
    "stats = stats.merge(short_stk, on = \"ticker\", how = \"left\")\n",
    "\n",
    "# filtering column\n",
    "stats = stats.loc[:,[\"stock_id\", \"enterpriseToRevenue\",\n",
    "                     \"enterpriseToEbitda\", \"enterpriseValue\",\n",
    "                     \"profitMargins\", \"netIncomeToCommon\",\n",
    "                     \"bookValue\", \"sharesOutstanding\",\n",
    "                     \"sharesPercentSharesOut\", \"heldPercentInstitutions\",\n",
    "                     \"heldPercentInsiders\", \"sharesShort\",\n",
    "                     \"shortRatio\", \"floatShares\", \"forwardEps\",\n",
    "                     \"trailingEps\", \"forwardPE\", \"trailingPE\",\n",
    "                     \"pegRatio\",\"priceToBook\", \"pricetoSales\", \"beta\"]]\n",
    "\n",
    "# dropping all null values\n",
    "stats = stats.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, value in stats.iterrows():\n",
    "    my_cursor.execute(\"INSERT INTO metrics (stock_id, date, enterpriseToRevenue,\\\n",
    "                                            enterpriseToEbitda, enterpriseValue,\\\n",
    "                                            profitMargins, netIncomeToCommon,\\\n",
    "                                            bookValue, sharesOutstanding,\\\n",
    "                                            sharesPercentSharesOut, heldPercentInstitutions,\\\n",
    "                                            heldPercentInsiders, sharesShort,\\\n",
    "                                            shortRatio, floatShares, forwardEps,\\\n",
    "                                            trailingEps, forwardPE, trailingPE,\\\n",
    "                                            pegRatio,priceToBook, pricetoSales, beta)\\\n",
    "                       VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\",\n",
    "                      (int(stats.loc[index, \"stock_id\"]),\n",
    "                       today,\n",
    "                       float(stats.loc[index, 'enterpriseToRevenue']),\n",
    "                       float(stats.loc[index, 'enterpriseToEbitda']),\n",
    "                       int(stats.loc[index, 'enterpriseValue']),\n",
    "                       float(stats.loc[index, 'profitMargins']),\n",
    "                       int(stats.loc[index, 'netIncomeToCommon']),\n",
    "                       float(stats.loc[index, 'bookValue']),\n",
    "                       int(stats.loc[index, 'sharesOutstanding']),\n",
    "                       float(stats.loc[index, 'sharesPercentSharesOut']),\n",
    "                       float(stats.loc[index, 'heldPercentInstitutions']),\n",
    "                       float(stats.loc[index, 'heldPercentInsiders']),\n",
    "                       int(stats.loc[index, 'sharesShort']),\n",
    "                       float(stats.loc[index, 'shortRatio']),\n",
    "                       int(stats.loc[index, 'floatShares']),\n",
    "                       float(stats.loc[index, 'forwardEps']),\n",
    "                       float(stats.loc[index, 'trailingEps']),\n",
    "                       float(stats.loc[index, 'forwardPE']),\n",
    "                       float(stats.loc[index, 'trailingPE']),\n",
    "                       float(stats.loc[index, 'pegRatio']),\n",
    "                       float(stats.loc[index, 'priceToBook']),\n",
    "                       float(stats.loc[index, 'pricetoSales']),\n",
    "                       float(stats.loc[index, 'beta']),\n",
    "                      )\n",
    "                     )\n",
    "    \n",
    "db.commit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
